{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJfzpMs9Kx1g"
      },
      "source": [
        "# Lab 1 - Data Manipulation with Pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div>\n",
        "<img src=\"../../images/pandas_logo.png\" width=\"700\"/>\n",
        "</div>\n",
        "\n",
        "_(Adapted from [CS109a: Introduction to Data Science](https://harvard-iacs.github.io/2019-CS109A/), [Pandas: Getting Started](https://pandas.pydata.org/docs/getting_started/index.html) & [GitHub: pandas_exercises](https://github.com/guipsamora))_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-XqeXlmLJB7"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "1.  Quick Overview\n",
        "2.  Learning Goals\n",
        "3.  Loading and Cleaning with Pandas\n",
        "4.  Parsing and Completing the Dataframe\n",
        "5.  Group Exercise: 1/2 hour in the Life of a Cardiologist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Quick Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "# Initialize a base path for us to use\n",
        "BASE_PATH = Path().cwd()\n",
        "\n",
        "BASE_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How is a DataFrame structured?\n",
        "\n",
        "<div>\n",
        "<img src=\"../../images/pandas_structure.png\" width=\"700\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Getting started with using pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"Name\": [\n",
        "            \"Braund, Mr. Owen Harris\",\n",
        "            \"Allen, Mr. William Henry\",\n",
        "            \"Bonnell, Miss. Elizabeth\",\n",
        "        ],\n",
        "        \"Age\": [22, 35, 58],\n",
        "        \"Sex\": [\"male\", \"male\", \"female\"],\n",
        "    }\n",
        ")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Age\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When selecting a single column of a pandas **`DataFrame`**, the result is a pandas **`Series`**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(df[\"Age\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A pandas **`Series`** has no column labels, as it is just a single column of a **`DataFrame`**. A Series does have row labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access the series by the index (row label)\n",
        "series = df[\"Age\"]\n",
        "\n",
        "series.loc[series.index % 2 == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How do we get data inside a DataFrame?\n",
        "\n",
        "<div>\n",
        "<img src=\"../../images/pandas_read_data.png\" width=\"700\"/>\n",
        "</div>\n",
        "\n",
        "Pretty simple, just use the (hopefully existing) **`read_<file_extension>`** method:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = BASE_PATH / \"data\"\n",
        "\n",
        "titanic = pd.read_csv(DATA_PATH / \"titanic\" / \"titanic.csv\")\n",
        "titanic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The great thing about this modular approach, is that if we know that the file extension maps one to one to an existing pandas method, then we have nothing to worry about.\n",
        "\n",
        "_Note: (If we were working with something like `xls` or `xlsx`, which are 'Microsoft Excel Open XML,' we would need map to the according method)_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(data_path: Path) -> List[pd.DataFrame]:\n",
        "    \"\"\"Loads all readable data files from a given directory into pandas DataFrames.\n",
        "\n",
        "    Args:\n",
        "        data_path (Path): Path object representing the base directory\n",
        "            containing the data files.\n",
        "\n",
        "    Returns:\n",
        "        List[pd.DataFrame]: A list of pandas DataFrames, one per successfully\n",
        "            loaded file.\n",
        "    \"\"\"\n",
        "    files_found = [path for path in data_path.glob(\"**/*\") if path.is_file()]\n",
        "\n",
        "    result = []\n",
        "    for found in files_found:\n",
        "        # Give us the file extension (.<ext>) and then remove the '.' leaving us only with <ext>\n",
        "        file_extension = found.suffix.lstrip(\".\")\n",
        "\n",
        "        read_method = getattr(pd, f\"read_{file_extension}\", default=None)\n",
        "        if callable(read_method):\n",
        "            result.append(read_method(found))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_data(DATA_PATH / \"titanic\")\n",
        "\n",
        "print(f\"Found: '{len(data)}' DataFrames\")\n",
        "data[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To check on how pandas interpreted each of the column data types can be done by requesting the pandas **`dtypes`** attribute:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, for each of the columns, the used data type is enlisted. The data types in this **`DataFrame`** are integers (**`int64`**), floats (**`float64`**) and strings (**`object`**).\n",
        "\n",
        "What is the (potential) consequence of **`dtype`** being **`object`** for strings? <br>\n",
        "$\\rightarrow$ Might not be the fastest approach\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object\n",
            "string\n",
            "\n",
            "Benchmarking .str.upper() ...\n",
            "object dtype:\n",
            "75.3 ms ± 1.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "string[pyarrow] dtype:\n",
            "9.36 ms ± 16.2 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "n = 1_000_000\n",
        "series_obj = pd.Series([\"hello\"] * n, dtype=object) # Numpy ndarray\n",
        "series_arrow = series_obj.astype(\"string[pyarrow]\") # pyarrow string\n",
        "\n",
        "print(series_obj.dtype)\n",
        "print(series_arrow.dtype)\n",
        "\n",
        "print(\"\\nBenchmarking .str.upper() ...\")\n",
        "\n",
        "print(\"object dtype:\")\n",
        "%timeit series_obj.str.upper()\n",
        "\n",
        "print(\"string[pyarrow] dtype:\")\n",
        "%timeit series_arrow.str.upper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How can you work with pandas DataFrames?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Titanic data set consists of the following data columns:\n",
        "\n",
        "- **`PassengerId`**: Id of every passenger.\n",
        "\n",
        "- **`Survived`**: Indication whether passenger survived. 0 for yes and 1 for no.\n",
        "\n",
        "- **`Pclass`**: One out of the 3 ticket classes: Class 1, Class 2 and Class 3.\n",
        "\n",
        "- **`Name`**: Name of passenger.\n",
        "\n",
        "- **`Sex`**: Gender of passenger.\n",
        "\n",
        "- **`Age`**: Age of passenger in years.\n",
        "\n",
        "- **`SibSp`**: Number of siblings or spouses aboard.\n",
        "\n",
        "- **`Parch`**: Number of parents or children aboard.\n",
        "\n",
        "- **`Ticket`**: Ticket number of passenger.\n",
        "\n",
        "- **`Fare`**: Indicating the fare.\n",
        "\n",
        "- **`Cabin`**: Cabin number of passenger.\n",
        "\n",
        "- **`Embarked`**: Port of embarkation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__DcV5I4LXLZ"
      },
      "source": [
        "### 1. Learning Goals\n",
        "\n",
        "About 6,000 odd \"best books\" were fetched and parsed from [Goodreads](https://www.goodreads.com/). The \"bestness\" of these books came from a proprietary formula used by Goodreads and published as a list on their web site.\n",
        "\n",
        "We parsed the page for each book and saved data from all these pages in a tabular format as a CSV file. In this lab we'll clean and further parse the data. We'll then do some exploratory data analysis to answer questions about these best books and popular genres.\n",
        "\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "- Load and systematically address missing values (encoded as `NaN`) values in our data set, for example, by removing observations associated with these values.\n",
        "- Parse columns in the dataframe to create new dataframe columns.\n",
        "\n",
        "#### 1.1 Basic workflow\n",
        "\n",
        "The basic workflow is as follows:\n",
        "\n",
        "1.  **Build** a DataFrame from the data (ideally, put all data in this object)\n",
        "2.  **Clean** the DataFrame. It should have the following properties:\n",
        "\n",
        "- Each row describes a single object\n",
        "- Each column describes a property of that object\n",
        "- Columns are numeric whenever appropriate\n",
        "- Columns contain atomic properties that cannot be further decomposed\n",
        "\n",
        "3.  Explore **global properties**. Use histograms, scatter plots, and aggregation functions to summarize the data.\n",
        "\n",
        "This process transforms your data into a format which is easier to work with, gives you a basic overview of the data's properties, and likely generates several questions for you to followup in subsequent analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTViTJ0dNAX0"
      },
      "source": [
        "### 2. Loading and Cleaning with Pandas\n",
        "\n",
        "Read in the `goodreads.csv` file, examine the data, and do any necessary data cleaning.\n",
        "\n",
        "Here is a description of the columns (in order) present in this csv file:\n",
        "\n",
        "- `rating:` The average rating on a 1-5 scale achieved by the book\n",
        "- `review_count`: The number of Goodreads users who reviewed this book\n",
        "- `isbn`: The ISBN code for the book\n",
        "- `booktype`: An internal Goodreads identifier for the book\n",
        "- `author_url`: The Goodreads (relative) URL for the author of the book\n",
        "- `year`: The year the book was published\n",
        "- `genre_urls`: A string with '|' separated relative URLS of Goodreads genre pages\n",
        "- `dir`: A directory identifier internal to the scraping code\n",
        "- `rating_count`: The number of ratings for this book (this is different from the number of reviews)\n",
        "- `name`: The name of the book\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efCOc_r4Ol4E"
      },
      "source": [
        "Let us see what issues we find with the data and resolve them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSVlEgCbOnqz"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9hA-sXRO5vb"
      },
      "source": [
        "After loading appropriate libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww4dC_2XO6G7"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "pd.set_option('display.width', 500)\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYhJeAlrPA61"
      },
      "source": [
        "#### 2.1 Cleaning: Reading in the data\n",
        "\n",
        "We read in and clean the data from `data/goodreads.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "0tb9Qy8eKrgg",
        "outputId": "1c6adb82-2841-4b63-fe24-bafe260b7179"
      },
      "outputs": [],
      "source": [
        "# Read the data into a dataframe\n",
        "df = pd.read_csv(\"data/goodreads.csv\", encoding=\"utf-8\")\n",
        "\n",
        "# Examine a few rows of the dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l04GnmjEPxaE"
      },
      "source": [
        "Oh dear. What are we looking at?\n",
        "\n",
        "That does not quite seem to be right. We are missing the `column names`. We need to add these in! But what are they?\n",
        "\n",
        "Here is a list of them in order:\n",
        "\n",
        "- `rating`, `review_count`, `isbn`, `booktype`, `author_url`, `year`, `genre_urls`, `dir`, `rating_count`, `name`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWtYCAAoP8Wt"
      },
      "source": [
        "#### Exercise: Load the Goodreads CSV file from `data/goodreads.csv` and\n",
        "\n",
        "Use these column names to load the dataframe properly! And then \"head\" the dataframe (Tip: check look at the [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) documentation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "3uU3plYwQKp8",
        "outputId": "c7b388a7-7c9a-4982-be5a-6a8a7b5585f1"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuxrN1-mWZax"
      },
      "source": [
        "#### 2.2 Cleaning: Examing the dataframe - Quick checks\n",
        "\n",
        "We should examine the dataframe to get a overall sense of the content.\n",
        "\n",
        "**Exercise**\n",
        "Lets check the types of the columns. What do you find?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "vT3E1FJjWjix",
        "outputId": "7102783e-11e2-42d6-d360-2ad7446e0d2a"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICnC1W6GXC4h"
      },
      "source": [
        "Notice that `review_count` and `rating_counts` are objects instead of ints, and the year is a float!\n",
        "\n",
        "There are a couple more quick sanity checks to perform on the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v39VAg_XXeEW",
        "outputId": "d6130cd5-0afd-4fc5-e2c0-dc7285bfff96"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSwKUx0lXolR"
      },
      "source": [
        "#### 2.3 Cleaning: Examining the dataframe - A deeper look\n",
        "\n",
        "Beyond performing checking some quick general properties of the data frame and looking at the first\n",
        "rows, we can dig a bit deeper into the values being stored. If you haven't already, check to see if there are any missing values in the data frame.\n",
        "\n",
        "Let's see for a column which seemed OK to us.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5GKjCSkXtHU",
        "outputId": "dc908845-fd19-4be1-8084-f2aa3b7bda24"
      },
      "outputs": [],
      "source": [
        "# Get a sense of how many missing values there are in the dataframe.\n",
        "for col in df.columns:\n",
        "    print(f\"{col}: {df[col].isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "NzhgB5IuX149",
        "outputId": "fbb855e2-c0c1-4a44-879e-73ff2dc3e73e"
      },
      "outputs": [],
      "source": [
        "# Alternative way\n",
        "df[df.rating.isnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzbHuuExYc8F"
      },
      "source": [
        "How does `pandas` or `numpy` handle missing values when we try to compute with data sets that include them?\n",
        "\n",
        "We'll now check if any of the other suspicious columns have missing values. Let's look at `year` and `review_count first`.\n",
        "\n",
        "One thing you can do is to try and convert to the type you expect the column to be. If something goes wrong, it likely means your data are bad.\n",
        "\n",
        "Lets test for missing data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yKmXNtoY83Q",
        "outputId": "2d80088e-3ceb-43ea-983b-bdd92e8973ad"
      },
      "outputs": [],
      "source": [
        "df[df.year.isnull()]\n",
        "\n",
        "df.year.isnull()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPjHESA4ZIJa"
      },
      "source": [
        "#### 2.4 Cleaning: Dealing with Missing Values\n",
        "\n",
        "How should we interpret 'missing' or 'invalid' values in the data (hint: look at where these values occur)? One approach is to simply exclude them from the dataframe. Is this appropriate for all 'missing' or 'invalid' values?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RGo7LMzZM0D"
      },
      "outputs": [],
      "source": [
        "# Treat the missing or invalid values in your dataframe\n",
        "#######\n",
        "\n",
        "df = df[df.year.notnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPROj8h1ZP3R"
      },
      "source": [
        "Ok so we have done some cleaning. What do things look like now? Notice the float has not yet changed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "CsXaexh3ZQmH",
        "outputId": "985d3437-8f31-49fe-ee43-78f14ae973c5"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tueOYgpZYlE",
        "outputId": "03730f9a-c449-4946-d8ca-926d93cf8d7f"
      },
      "outputs": [],
      "source": [
        "print(df.year.isnull().sum())\n",
        "df.shape  # We removed seven rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Converting types\n",
        "\n",
        "Ok so lets adjust those types. Convert them to `ints`. If the type conversion fails, we now know we have further problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your Code Here\n",
        "df.rating = df.rating.astype(int)\n",
        "df.review_count = df.review_count.astype(int)\n",
        "df.year = df.year.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once you do this, we seem to be good on these columns (no errors in conversion). Lets look:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great, now let's do it for some other columns with `NaN` that should be `strings`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.loc[df.genre_urls.isnull(), \"genre_urls\"] = \"\"\n",
        "df.loc[df.isbn.isnull(), \"isbn\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Parsing and Completing the Data Frame\n",
        "\n",
        "We will parse the `author` column from the author_url and `genres` column from the genre_urls.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Examine an example `author_url` and reason about which sequence of string operations must be performed in order to isolate the author's name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the first author_url\n",
        "author_string = df.author_url[1]\n",
        "author_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Extracting all Authors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test out some string operations to isolate the author name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets wrap the above code into a function which we will then use\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Parsing out the genres\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.genre_urls.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adjust the genres to be of type `<genre_1>|<genre_2>|...|<genre_n>`, e.g. `young-adult|science-fiction|fantasy`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use map again to create a new \"genres\" column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Titanic dataset\n",
        "\n",
        "The `titanic.csv` file contains data for 887 passengers on the Titanic. Each row represents one person. The columns describe different attributes about the person including whether they survived, their age, their on-board class, their sex, and the fare they paid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic = sns.load_dataset(\"titanic\")\n",
        "titanic.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "titanic.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Remove the following features:\n",
        "\n",
        "`'embarked', 'who', 'adult_male', 'embark_town', 'alive', 'alone'`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Find for how many passengeres we do not have their deck information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your ode here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Histograms\n",
        "\n",
        "#### Plotting one variable's distribution (categorical and continous)\n",
        "\n",
        "The most convenient way to take a quick look at a univariate distribution in `seaborn` is the `distplot()` function. By default, this will draw a histogram and fit a kernel density estimate (KDE).\n",
        "\n",
        "A histogram displays a quantitative (numerical) distribution by showing the number (or percentage) of the data values that fall in specified intervals. The intervals are on the x-axis and the number of values falling in each interval, shown as either a number or percentage, are represented by bars drawn above the corresponding intervals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# What was the age distribution among passengers in the Titanic?\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "f, ax = plt.subplots(1, 1, figsize=(8, 3))\n",
        "ax = sns.histplot(titanic.age, kde=False, bins=20)\n",
        "\n",
        "\n",
        "ax.set(xlim=(0, 90))\n",
        "ax.set_ylabel(\"counts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise (pandas trick): Count all the infants on board (age less than 3) and all the children ages 5-10.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your Code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `pandas` Tricks\n",
        "\n",
        "The copy() method on pandas objects copies the underlying data (though not the axis indexes, since they are immutable)\n",
        "and returns a new object. Note that it is seldom necessary to copy objects. For example, there are only a\n",
        "handful of ways to alter a DataFrame in-place:\n",
        "\n",
        "- Inserting, deleting, or modifying a column.\n",
        "- Assigning to the index or columns attributes.\n",
        "- For homogeneous data, directly modifying the values via the values attribute or advanced indexing.\n",
        "\n",
        "To be clear, no pandas method has the side effect of modifying your data; almost every method returns a new object,\n",
        "leaving the original object untouched. If the data is modified, it is because you did so explicitly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Group Exercise: 1/2 hour in the Life of a Cardiologist\n",
        "\n",
        "Try each exercise on your own and then discuss with your peers sitting at your table.\n",
        "\n",
        "Visualize and explore the data. Use `.describe()` to look at your data and also examine if you have any missing values.\n",
        "What is the actual number of feature variables after converting categorical variables to dummy ones?\n",
        "\n",
        "**List of available variables (includes target variable `num`):**\n",
        "\n",
        "- **age**: continuous\n",
        "- **sex**: categorical, 2 values {0: female, 1: male}\n",
        "- **cp** (chest pain type): categorical, 4 values\n",
        "  {1: typical angina, 2: atypical angina, 3: non-angina, 4: asymptomatic angina}\n",
        "- **restbp** (resting blood pressure on admission to hospital): continuous (mmHg)\n",
        "- **chol (serum cholesterol level)**: continuous (mg/dl)\n",
        "- **fbs** (fasting blood sugar): categorical, 2 values {0: <= 120 mg/dl, 1: > 120 mg/dl}\n",
        "- **restecg** (resting electrocardiography): categorical, 3 values\n",
        "  {0: normal, 1: ST-T wave abnormality, 2: left ventricular hypertrophy}\n",
        "- **thalach** (maximum heart rate achieved): continuous\n",
        "- **exang** (exercise induced angina): categorical, 2 values {0: no, 1: yes}\n",
        "- **oldpeak** (ST depression induced by exercise relative to rest): continuous\n",
        "- **slope** (slope of peak exercise ST segment): categorical, 3 values {1: upsloping, 2: flat, 3: downsloping}\n",
        "- **ca** (number of major vessels colored by fluoroscopy): discrete (0,1,2,3)\n",
        "- **thal**: categorical, 3 values {3: normal, 6: fixed defect, 7: reversible defect}\n",
        "- **num** (diagnosis of heart disease): categorical, 5 values {\n",
        "  0: less than 50% narrowing in any major vessel,\n",
        "  1-4: more than 50% narrowing in 1-4 vessels\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "columns_heart = [\"age\", \"sex\", \"cp\", \"restbp\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]\n",
        "\n",
        "heart_df = pd.read_csv(\"data/heart_disease.csv\", header=None, names=columns_heart)\n",
        "heart_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A practical Introduction to seaborn\n",
        "\n",
        "<div>\n",
        "<a href=\"https://seaborn.pydata.org/examples/index.html\">\n",
        "<img src=\"images/seaborn.png\" width=\"700\"/>\n",
        "</a>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Answer the following question using plots\n",
        "\n",
        "1.  At what ages do people seek cardiological exams?\n",
        "2.  Do men seek help more than women?\n",
        "3.  Examine the variables. How do they relate to one another?\n",
        "4.  (Variation on 02): What % of men and women seek cardio exams?\n",
        "5.  Does resting blood pressure increase with age?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Pandas trick: `.replace`** The response variable (num) is categorical with 5 values, but we don't have enough data to predict all the categories. <BR> Therefore we'll replace `num` with `hd` (heart disease): **categorical, 2 values {0: no, 1: yes}**. <BR>\n",
        "Use the code below (take a minute to understand how it works, it's very useful!):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replace response variable values with a binary response (1: heart disease(hd) or 0: not)\n",
        "heart_df[\"num\"].replace(to_replace=[1, 2, 3, 4], value=1, inplace=True)\n",
        "\n",
        "# Rename column for clarity\n",
        "heart_df = heart_df.rename(columns={\"num\": \"hd\"})\n",
        "heart_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the features\n",
        "heart_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "heart_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: At which ages do people seek cardiological exams?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Which of the listed genders seeks more help than the other?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: What percentage of men and women seek cardio exams?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Examine the variables. How do they relate to one another?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exercise: Does resting blood pressure increase with age?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
